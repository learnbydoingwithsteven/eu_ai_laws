# Italian Garante Privacy Guidelines on Artificial Intelligence and Data Protection (2024)

## Section 1 — Lawfulness and purpose limitation
1. Processing of personal data within AI systems must be grounded on an appropriate legal basis under the GDPR and the Italian Data Protection Code.
2. Controllers must document the specific purposes for algorithmic training, validation and deployment, ensuring compatibility with the original data collection.

## Section 2 — Transparency and information duties
1. Controllers must provide layered information notices detailing the logic involved in AI-driven decisions, the significance and envisaged consequences for data subjects.
2. Transparency obligations extend to informing individuals when conversational agents, biometric categorisation or emotion recognition tools are in use.

## Section 3 — Accountability and documentation
1. Organisations must maintain registers describing AI use cases, data flows, DPIA outcomes and mitigation measures.
2. Technical and organisational safeguards shall be proportionate to the scale and sensitivity of the processing.

## Section 4 — Human oversight and safeguards
1. Controllers shall ensure trained human reviewers can intervene, suspend or override AI outputs that present anomalies or risks to rights and freedoms.
2. Oversight procedures must include periodic audits, scenario testing and clear escalation paths to the data protection officer.

## Section 5 — Coordination with national authorities
1. Significant AI deployments must be notified to the Garante when high risks are identified, including the submission of DPIAs and mitigation plans.
2. Controllers shall cooperate with national and sectoral authorities, promptly sharing information on incidents, corrective measures and user complaints.
